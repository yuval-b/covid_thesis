{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d929c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for estimating C from international arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de84451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63dfe344",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import up sound alert dependencies\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "## Insert whatever audio file you want above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5695f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekbyweek = os.listdir('/Volumes/HardDrive/weekbyweek/')\n",
    "for item in weekbyweek:\n",
    "    if '._' in item:\n",
    "        weekbyweek.remove(item)\n",
    "        \n",
    "for item in weekbyweek:\n",
    "    if '._' in item:\n",
    "        weekbyweek.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378742a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrivals(x):\n",
    "    truth = True\n",
    "    box1 = [112, 129, -45, -12]\n",
    "    box2 = [129, 147, -45, -9.8]\n",
    "    box3 = [147, 156, -45, -16]\n",
    "    box4 = [112, 156, -45, -9.8]\n",
    "    # Is the end point of the inside WA?\n",
    "    if (box1[2] < x[5] < box1[3]) & (box1[0]< x[6] < box1[1]):\n",
    "        # Is the start point of the line outside the three Australian boxes?\n",
    "        if (x[2] < box4[2] or x[2] > box4[3]) or (x[3] < box4[0] or x[3] > box4[1]):\n",
    "            truth = False\n",
    "    return truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e126bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inbox(df):\n",
    "    inds = []\n",
    "    for row in df.itertuples():\n",
    "        if arrivals(list(row[1:])):\n",
    "            inds.append(row[0])\n",
    "    df = df.drop(inds)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492bc2a",
   "metadata": {},
   "source": [
    "## June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b24900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at June 2021\n",
    "jun = []\n",
    "for item in weekbyweek:\n",
    "    if '202106'  in item:\n",
    "        jun.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2135258",
   "metadata": {},
   "outputs": [],
   "source": [
    "jun = sorted(jun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5ec2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_epi_mobility_covid_20210530_20210605.txt',\n",
       " 'agg_epi_mobility_covid_20210606_20210612.txt',\n",
       " 'agg_epi_mobility_covid_20210613_20210619.txt',\n",
       " 'agg_epi_mobility_covid_20210620_20210626.txt',\n",
       " 'agg_epi_mobility_covid_20210627_20210703.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc6ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "incoming = []\n",
    "for i in range(len(jun)):\n",
    "    name = jun[i]\n",
    "    print(i)\n",
    "    df = pd.read_csv('/Volumes/HardDrive/weekbyweek/' + name, header = None)\n",
    "    df = inbox(df)\n",
    "\n",
    "    incoming.append(sum([math.exp(i) for i in list(df[7])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f31e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8099435391624914e-07, 2.0800577358710846e-07, 2.070097382710361e-07, 2.070097382710361e-07, 1.4700488785590887e-07]\n",
      "9.500244919013387e-07\n"
     ]
    }
   ],
   "source": [
    "print(incoming)\n",
    "print(sum(incoming))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a23d47",
   "metadata": {},
   "source": [
    "Now, we have the total international flow from internationally into Western Australia from May 30th to July 3rd. According to this link, https://www.abs.gov.au/statistics/industry/tourism-and-transport/overseas-travel-statistics-provisional/latest-release, 1760 people were admitted into the state as international arrivals in June 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c58ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow= sum(incoming)\n",
    "flow = flow*30/34 #normalise to ignore the excess dates\n",
    "C = 7220/flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2f46e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613111279.15263\n"
     ]
    }
   ],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dc339",
   "metadata": {},
   "source": [
    "## May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f382a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at May 2021\n",
    "may = []\n",
    "for item in weekbyweek:\n",
    "    if '202105'  in item:\n",
    "        may.append(item)\n",
    "\n",
    "may = sorted(may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7cf813",
   "metadata": {},
   "outputs": [],
   "source": [
    "may = may[1:-1] #The first and the last only have the two first and last day of May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bef9d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "incoming = []\n",
    "for i in range(len(may)):\n",
    "    name = may[i]\n",
    "    print(i)\n",
    "    df = pd.read_csv('/Volumes/HardDrive/weekbyweek/' + name, header = None)\n",
    "    df = inbox(df)\n",
    "\n",
    "    incoming.append(sum([math.exp(i) for i in list(df[7])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5251fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9386321893.408083\n"
     ]
    }
   ],
   "source": [
    "flow= sum(incoming)\n",
    "flow = flow*31/28 #normalise\n",
    "C = 5830/flow\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6015e07",
   "metadata": {},
   "source": [
    "## June 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4703ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at June 2020\n",
    "jun = []\n",
    "for item in weekbyweek:\n",
    "    if '202006'  in item:\n",
    "        jun.append(item)\n",
    "\n",
    "jun = sorted(jun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28be930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_epi_mobility_covid_20200531_20200606.txt',\n",
       " 'agg_epi_mobility_covid_20200607_20200613.txt',\n",
       " 'agg_epi_mobility_covid_20200614_20200620.txt',\n",
       " 'agg_epi_mobility_covid_20200621_20200627.txt',\n",
       " 'agg_epi_mobility_covid_20200628_20200704.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dd1b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "incoming = []\n",
    "for i in range(len(jun)):\n",
    "    name = jun[i]\n",
    "    print(i)\n",
    "    df = pd.read_csv('/Volumes/HardDrive/weekbyweek/' + name, header = None)\n",
    "    df = inbox(df)\n",
    "\n",
    "    incoming.append(sum([math.exp(i) for i in list(df[7])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0de41f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "834c5543",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ys/xd1k0y7j01xghctdv8ktdd900000gn/T/ipykernel_41141/2872848479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;31m#normalise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1760\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "flow= sum(incoming)\n",
    "flow = flow*30/35 #normalise\n",
    "C = 1760/flow\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb17011",
   "metadata": {},
   "source": [
    "Ie Google didn't pick up enough travellers coming in to WA in June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b993f",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aeeeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 3 C's, find average\n",
    "C1 = 8613111279.15263\n",
    "C2 = 9386321893.408083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53add789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999716586.280357\n"
     ]
    }
   ],
   "source": [
    "print((C1+C2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763db4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fdabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc2510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our estimate for C is 9*10^9 (which I think may be worryingly big...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e18878",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = os.listdir('/Volumes/HardDrive/New_Workflow/53_towns_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "769d8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "town58 = []\n",
    "for t in range(len(to)):\n",
    "    if '._' not in to[t]:\n",
    "        town58.append(to[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a073fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 45\n",
      "0 1 31\n",
      "0 50 0\n",
      "5 50 0\n",
      "6 50 0\n",
      "7 50 0\n",
      "8 50 0\n",
      "10 50 0\n",
      "11 50 0\n",
      "13 50 0\n",
      "15 50 0\n",
      "16 50 0\n",
      "17 50 0\n",
      "21 50 0\n",
      "25 50 0\n",
      "29 50 0\n",
      "34 50 0\n",
      "36 50 0\n",
      "37 50 0\n",
      "38 50 0\n",
      "1.7542080297077854e-05\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "for i in range(len(town58)):\n",
    "    \n",
    "    df = pd.read_csv('/Volumes/HardDrive/New_Workflow/53_towns_network/'+town58[i])\n",
    "    \n",
    "    listwise = df.to_numpy().tolist()\n",
    "    \n",
    "    for j in range(len(listwise)):\n",
    "        item = listwise[j]\n",
    "        if max(item) > maxx:\n",
    "            k = item.index(max(item))\n",
    "            print(i,j,k)\n",
    "            maxx = max(item)\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae44b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157873.75100255536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_peeps / C = flow\n",
    "maxx * 8999716586"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848cde4",
   "metadata": {},
   "source": [
    "So the largest flow is 158 thousand people... may be a bit too much? Maybe just accept it? Maybe will get smoothed out by Kalman filtering?? Keep going for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba62c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest flow after kalman filtering and stochasticising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b360d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = os.listdir('/Volumes/HardDrive/New_Workflow/53_towns_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32aa049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "town58 = []\n",
    "for t in range(len(to)):\n",
    "    if '._' not in to[t]:\n",
    "        town58.append(to[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b47298e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(town58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cda96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Town_Flow_20200322_20200328.csv 0 51\n",
      "Town_Flow_20200816_20200822.csv 0 51\n",
      "Town_Flow_20200823_20200829.csv 0 51\n",
      "Town_Flow_20200830_20200905.csv 0 51\n",
      "Town_Flow_20200906_20200912.csv 0 51\n",
      "Town_Flow_20200913_20200919.csv 0 51\n",
      "Town_Flow_20200920_20200926.csv 0 51\n",
      "Town_Flow_20201011_20201017.csv 0 51\n",
      "Town_Flow_20201018_20201024.csv 0 51\n",
      "Town_Flow_20201025_20201031.csv 0 51\n",
      "Town_Flow_20201101_20201107.csv 0 51\n",
      "Town_Flow_20201115_20201121.csv 0 51\n",
      "Town_Flow_20201122_20201128.csv 0 51\n",
      "Town_Flow_20201129_20201205.csv 0 51\n",
      "Town_Flow_20201206_20201212.csv 0 51\n",
      "Town_Flow_20201213_20201219.csv 0 51\n",
      "Town_Flow_20211212_20211218.csv 0 51\n",
      "Town_Flow_20211219_20211225.csv 0 51\n",
      "1.3647595725200537e-05\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "for i in range(len(town58)):\n",
    "    \n",
    "    df = pd.read_csv('/Volumes/HardDrive/New_Workflow/stochastic_53/'+town58[i], header = None)\n",
    "    \n",
    "    listwise = df.to_numpy().tolist()\n",
    "    \n",
    "    for j in range(len(listwise)):\n",
    "        item = listwise[j]\n",
    "        if max(item) > maxx:\n",
    "            k = item.index(max(item))\n",
    "            print(town58[i],j,k)\n",
    "            maxx = max(item)\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6f9e7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122824.49360710997"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx * 8999716586"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c20904",
   "metadata": {},
   "source": [
    "So after kalman filtering and stochasticising, the largest flow between two towns is 123 thousand people... still quite big- but the caveat we put on it is that it's Perth to Mandurah flow- which should be expected to be big! (Also note that Perth to Madurah flow is pretty much just as big for that week, which is good cos Mandurah is recorded as only having 80k people)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
